---
phase: 08-residual-rl-and-learning
plan: 03
type: execute
wave: 2
depends_on: [08-01, 08-02]
files_modified:
  - evcc-smartload/rootfs/app/reaction_timing.py
  - evcc-smartload/rootfs/app/main.py
  - evcc-smartload/rootfs/app/optimizer/planner.py
  - evcc-smartload/rootfs/app/dynamic_buffer.py
autonomous: true
requirements: [LERN-03, LERN-04]

must_haves:
  truths:
    - "ReactionTimingTracker learns whether plan deviations self-correct or require intervention"
    - "All four learners (ResidualRLAgent, SeasonalLearner, ForecastReliabilityTracker, ReactionTimingTracker) are instantiated and wired into main.py"
    - "RL shadow mode logic gates correction application in the decision loop"
    - "Confidence factors from ForecastReliabilityTracker are passed into HorizonPlanner"
    - "PV reliability factor is passed into DynamicBufferCalc.step()"
    - "RL correction logging is skipped when Boost override is active"
  artifacts:
    - path: "evcc-smartload/rootfs/app/reaction_timing.py"
      provides: "ReactionTimingTracker with deviation classification and EMA threshold"
      contains: "class ReactionTimingTracker"
    - path: "evcc-smartload/rootfs/app/main.py"
      provides: "All Phase 8 learners instantiated, shadow mode branching, forecast confidence wiring"
      contains: "ResidualRLAgent"
    - path: "evcc-smartload/rootfs/app/optimizer/planner.py"
      provides: "confidence_factors parameter in plan() method"
      contains: "confidence_factors"
    - path: "evcc-smartload/rootfs/app/dynamic_buffer.py"
      provides: "pv_reliability_factor parameter in step() method"
      contains: "pv_reliability_factor"
  key_links:
    - from: "evcc-smartload/rootfs/app/main.py"
      to: "evcc-smartload/rootfs/app/rl_agent.py"
      via: "ResidualRLAgent.select_delta() called each cycle; mode check gates apply_correction()"
      pattern: "rl_agent\\.select_delta"
    - from: "evcc-smartload/rootfs/app/main.py"
      to: "evcc-smartload/rootfs/app/forecast_reliability.py"
      via: "forecast_reliability.update() called with actual vs forecast each cycle"
      pattern: "forecast_reliability\\.update"
    - from: "evcc-smartload/rootfs/app/main.py"
      to: "evcc-smartload/rootfs/app/optimizer/planner.py"
      via: "confidence_factors dict passed to horizon_planner.plan()"
      pattern: "confidence_factors.*planner"
    - from: "evcc-smartload/rootfs/app/main.py"
      to: "evcc-smartload/rootfs/app/dynamic_buffer.py"
      via: "pv_reliability_factor passed to buffer_calc.step()"
      pattern: "pv_reliability_factor"
---

<objective>
Create ReactionTimingTracker, wire all four learning subsystems into the main decision loop, integrate confidence factors into HorizonPlanner and DynamicBufferCalc, and implement shadow mode branching for RL corrections.

Purpose: LERN-03 requires adaptive reaction timing. LERN-04 completion requires confidence factors actually flowing into the planner and buffer calc. This plan also wires Plans 01 and 02 outputs into the live system.
Output: reaction_timing.py, updated main.py with all learner wiring, updated planner.py and dynamic_buffer.py with confidence factor inputs
</objective>

<execution_context>
@C:/Users/nicok/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/nicok/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-residual-rl-and-learning/08-RESEARCH.md
@.planning/phases/04-predictive-planner/04-02-SUMMARY.md
@.planning/phases/05-dynamic-buffer/05-01-SUMMARY.md
@evcc-smartload/rootfs/app/main.py
@evcc-smartload/rootfs/app/optimizer/planner.py
@evcc-smartload/rootfs/app/dynamic_buffer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ReactionTimingTracker and extend planner/buffer with confidence factors</name>
  <files>
    evcc-smartload/rootfs/app/reaction_timing.py
    evcc-smartload/rootfs/app/optimizer/planner.py
    evcc-smartload/rootfs/app/dynamic_buffer.py
  </files>
  <action>
**A. Create reaction_timing.py:**

Create `ReactionTimingTracker` class following DynamicBufferCalc persistence pattern:

1. **DeviationEpisode:** Dataclass with `timestamp` (datetime), `plan_action` (str: "bat_charge"/"bat_hold"/"bat_discharge"/"ev_charge"/"ev_idle"), `actual_action` (str), `self_corrected` (bool), `resolved_in_cycles` (int).

2. **Public methods:**
   - `__init__()`: Initialize episodes list, EMA state, threading.Lock, load from disk.
   - `update(plan_action: str, actual_action: str)`: Compare plan vs actual. If they match, no deviation. If they diverge, record a deviation episode. On the NEXT call after a deviation, check if plan and actual now align — if so, mark previous episode as `self_corrected=True`. Update EMA.
   - `should_replan_immediately() -> bool`: Return True if `_ema_self_correction_rate < _wait_threshold`. This means most deviations do NOT self-correct, so re-planning is warranted.
   - `get_stats() -> dict`: Return `{"ema_self_correction_rate": float, "wait_threshold": float, "total_episodes": int, "should_replan": bool}`.
   - `save()`: Atomic write to `/data/smartprice_reaction_timing.json`. Store EMA state, threshold, recent episodes (last 100).
   - `_load()`: Load from file. Graceful fallback.

3. **EMA parameters:** `alpha=0.05` (slow-moving). Initial `_ema_self_correction_rate = 0.5` (neutral). `_wait_threshold = 0.6` (re-plan if fewer than 60% of deviations self-correct).

4. **Persistence path:** `REACTION_TIMING_PATH = "/data/smartprice_reaction_timing.json"`

5. **Thread safety:** `threading.Lock()` with I/O outside lock.

**B. Extend HorizonPlanner.plan() with confidence_factors:**

In `optimizer/planner.py`, add optional `confidence_factors: dict = None` parameter to the `plan()` method. When provided:

- Apply `confidence_factors.get("pv", 1.0)` as a multiplier on the PV surplus values used in the LP objective. Lower PV confidence means the planner trusts PV forecasts less and acts more conservatively with battery discharge timing.
- Do NOT scale price coefficients directly (research recommendation: price confidence affects planning via DynamicBufferCalc, not LP coefficients).
- If `confidence_factors` is None or missing keys, default to 1.0 for each (backward compatible).

**C. Extend DynamicBufferCalc.step() with pv_reliability_factor:**

In `dynamic_buffer.py`, add optional `pv_reliability_factor: float = 1.0` parameter to `step()`. Apply as a multiplier on the `pv_confidence` input:
```python
effective_confidence = pv_confidence * pv_reliability_factor
```
This means if ForecastReliabilityTracker says PV forecasts are only 70% reliable, the buffer calc gets a reduced confidence, keeping the buffer higher.
  </action>
  <verify>
    <automated>cd /c/users/nicok/projects/smartload && python -c "
import sys; sys.path.insert(0, 'evcc-smartload/rootfs/app')
# Check ReactionTimingTracker
from reaction_timing import ReactionTimingTracker
tracker = ReactionTimingTracker.__new__(ReactionTimingTracker)
assert hasattr(tracker, 'update')
assert hasattr(tracker, 'should_replan_immediately')
assert hasattr(tracker, 'get_stats')
assert hasattr(tracker, 'save')
print('PASS: ReactionTimingTracker structure verified')
# Check planner signature
import ast
src = open('evcc-smartload/rootfs/app/optimizer/planner.py').read()
tree = ast.parse(src)
for node in ast.walk(tree):
    if isinstance(node, ast.FunctionDef) and node.name == 'plan':
        args = [a.arg for a in node.args.args]
        assert 'confidence_factors' in args or any('confidence_factors' in (getattr(kw, 'arg', '') or '') for kw in (node.args.kwonlyargs or [])), 'plan() missing confidence_factors param'
        break
print('PASS: HorizonPlanner.plan() has confidence_factors parameter')
# Check dynamic_buffer signature
src2 = open('evcc-smartload/rootfs/app/dynamic_buffer.py').read()
assert 'pv_reliability_factor' in src2, 'dynamic_buffer.py missing pv_reliability_factor'
print('PASS: DynamicBufferCalc.step() has pv_reliability_factor parameter')
"
    </automated>
    <manual>Verify reaction_timing.py, planner.py confidence_factors, dynamic_buffer.py pv_reliability_factor</manual>
  </verify>
  <done>ReactionTimingTracker exists with EMA-based deviation classification; HorizonPlanner.plan() accepts confidence_factors dict; DynamicBufferCalc.step() accepts pv_reliability_factor</done>
</task>

<task type="auto">
  <name>Task 2: Wire all Phase 8 learners into main.py decision loop</name>
  <files>evcc-smartload/rootfs/app/main.py</files>
  <action>
Wire all four Phase 8 learning subsystems into the main decision loop in main.py. This is the integration task that connects Plans 01 and 02 outputs to the live system.

**1. Imports (add at top of file):**
```python
from rl_agent import ResidualRLAgent  # replaces DQNAgent import
from seasonal_learner import SeasonalLearner
from forecast_reliability import ForecastReliabilityTracker
from reaction_timing import ReactionTimingTracker
```
Remove or comment out `from rl_agent import DQNAgent` import.

**2. Initialization (in startup section, after existing component init):**
Initialize all learners with graceful try/except fallback (matching horizon_planner pattern):

```python
# Phase 8: Learning subsystems
seasonal_learner = None
try:
    seasonal_learner = SeasonalLearner()
    log("info", f"SeasonalLearner: {seasonal_learner.populated_cell_count()} cells populated")
except Exception as e:
    log("warning", f"SeasonalLearner init failed: {e}")

forecast_reliability = None
try:
    forecast_reliability = ForecastReliabilityTracker()
    log("info", "ForecastReliabilityTracker initialized")
except Exception as e:
    log("warning", f"ForecastReliabilityTracker init failed: {e}")

reaction_timing = None
try:
    reaction_timing = ReactionTimingTracker()
    log("info", "ReactionTimingTracker initialized")
except Exception as e:
    log("warning", f"ReactionTimingTracker init failed: {e}")
```

Replace `rl_agent = DQNAgent(cfg)` with `rl_agent = ResidualRLAgent(cfg)`. Wrap in try/except with graceful fallback (rl_agent = None if init fails).

**3. Inject into web server (late attribute assignment):**
```python
srv.seasonal_learner = seasonal_learner
srv.forecast_reliability = forecast_reliability
srv.reaction_timing = reaction_timing
```
(rl_agent is already injected as `srv.rl`)

**4. Decision loop — Forecast reliability updates (after forecasters run, before planner):**
```python
if forecast_reliability is not None:
    # Update PV reliability (convert W -> kW, Pitfall 4)
    if pv_96 is not None and state.pv_power is not None:
        actual_pv_kw = state.pv_power / 1000.0
        current_slot_idx = _current_slot_index()  # helper: (hour * 4 + minute // 15)
        if 0 <= current_slot_idx < len(pv_96):
            forecast_reliability.update("pv", actual=actual_pv_kw, forecast=pv_96[current_slot_idx])

    # Update consumption reliability
    if consumption_96 is not None and state.home_power is not None:
        current_slot_idx = _current_slot_index()
        if 0 <= current_slot_idx < len(consumption_96):
            forecast_reliability.update("consumption", actual=state.home_power, forecast=consumption_96[current_slot_idx])

    # Update price reliability
    if tariffs and state.current_price is not None:
        forecast_reliability.update("price", actual=state.current_price, forecast=float(tariffs[0].get("value", state.current_price)))
```

Add helper `_current_slot_index()` if not already present: returns `now.hour * 4 + now.minute // 15`.

**5. Decision loop — Pass confidence factors to planner:**
```python
confidence_factors = None
if forecast_reliability is not None:
    confidence_factors = {
        "pv": forecast_reliability.get_confidence("pv"),
        "consumption": forecast_reliability.get_confidence("consumption"),
        "price": forecast_reliability.get_confidence("price"),
    }

# In HorizonPlanner.plan() call, add confidence_factors parameter:
plan = horizon_planner.plan(..., confidence_factors=confidence_factors)
```

**6. Decision loop — Pass PV reliability to buffer calc:**
```python
pv_reliability = 1.0
if forecast_reliability is not None:
    pv_reliability = forecast_reliability.get_confidence("pv")

# In buffer_calc.step() call, add pv_reliability_factor parameter:
buffer_result = buffer_calc.step(..., pv_reliability_factor=pv_reliability)
```

**7. Decision loop — Shadow mode RL branching (replaces existing RL path):**
```python
# Skip RL entirely if agent not available or override active
override_active = override_manager.get_status()["active"] if override_manager else False

if rl_agent is not None and not override_active:
    bat_delta_ct, ev_delta_ct = rl_agent.select_delta(state, explore=True)

    if rl_agent.mode == "shadow":
        # Log correction but do NOT apply
        rl_agent.log_shadow_correction(
            bat_delta_ct, ev_delta_ct,
            plan_bat_price_ct=(lp_action.battery_limit_eur or 0) * 100,
            plan_ev_price_ct=(lp_action.ev_limit_eur or 0) * 100,
            state=state,
        )
        final = lp_action  # unmodified LP plan
    elif rl_agent.mode == "advisory":
        adj_bat_ct, adj_ev_ct = rl_agent.apply_correction(
            plan_bat_price_ct=(lp_action.battery_limit_eur or 0) * 100,
            plan_ev_price_ct=(lp_action.ev_limit_eur or 0) * 100,
            delta_bat_ct=bat_delta_ct,
            delta_ev_ct=ev_delta_ct,
            state=state,
        )
        # Create adjusted action with corrected thresholds
        from state import Action
        final = Action(
            battery_action=lp_action.battery_action,
            battery_limit_eur=adj_bat_ct / 100,
            ev_action=lp_action.ev_action,
            ev_limit_eur=adj_ev_ct / 100,
        )
```
NOTE: Remove or replace the old DQNAgent.select_action() call and per-device mode switching (RLDeviceController) that existed before. The ResidualRLAgent is the sole RL path now.

**8. Decision loop — SeasonalLearner update (after action execution, where cost is known):**
```python
if seasonal_learner is not None and plan is not None:
    # plan_error = actual_cost - plan_cost (positive = plan was optimistic)
    plan_slot0_cost = _compute_slot0_cost(plan, state)
    actual_slot0_cost = _compute_actual_slot0_cost(state)
    if plan_slot0_cost is not None and actual_slot0_cost is not None:
        plan_error = actual_slot0_cost - plan_slot0_cost
        seasonal_learner.update(datetime.now(timezone.utc), plan_error)
```

Add helpers:
- `_compute_slot0_cost(plan, state) -> Optional[float]`: slot0 price * (bat_charge_kw + ev_charge_kw) * 0.25
- `_compute_actual_slot0_cost(state) -> Optional[float]`: current_price * actual_grid_power_kw * 0.25

**9. Decision loop — ReactionTimingTracker update:**
```python
if reaction_timing is not None and plan is not None:
    plan_action_str = _action_to_str(lp_action)  # "bat_charge"/"bat_hold"/"ev_charge"/etc
    actual_action_str = _action_to_str(final)
    reaction_timing.update(plan_action_str, actual_action_str)
```

**10. Decision loop — Comparator residual update:**
```python
if comparator is not None and rl_agent is not None and not override_active:
    plan_slot0_cost = _compute_slot0_cost(plan, state)
    actual_slot0_cost = _compute_actual_slot0_cost(state)
    if plan_slot0_cost is not None and actual_slot0_cost is not None:
        comparator.compare_residual(plan_slot0_cost, actual_slot0_cost, bat_delta_ct, ev_delta_ct)
```

**11. Decision loop — RL learning step:**
```python
if rl_agent is not None and not override_active:
    reward = rl_agent.calculate_reward(plan_slot0_cost or 0, actual_slot0_cost or 0)
    rl_agent.learn_from_correction(state, action_idx, reward, next_state)
```

**12. Decision loop — Auto-promotion check (once per cycle when shadow elapsed):**
```python
if rl_agent is not None and rl_agent.mode == "shadow":
    if rl_agent.shadow_elapsed_days() >= 30:
        audit_result = rl_agent.run_constraint_audit()
        rl_agent.maybe_promote(audit_result)
```
  </action>
  <verify>
    <automated>cd /c/users/nicok/projects/smartload && python -c "
import ast
src = open('evcc-smartload/rootfs/app/main.py').read()
# Check imports
assert 'ResidualRLAgent' in src, 'Missing ResidualRLAgent import'
assert 'SeasonalLearner' in src, 'Missing SeasonalLearner import'
assert 'ForecastReliabilityTracker' in src, 'Missing ForecastReliabilityTracker import'
assert 'ReactionTimingTracker' in src, 'Missing ReactionTimingTracker import'
# Check shadow mode branching
assert 'shadow' in src and 'advisory' in src, 'Missing shadow/advisory mode branching'
# Check confidence_factors wiring
assert 'confidence_factors' in src, 'Missing confidence_factors wiring'
# Check override_active guard for RL
assert 'override_active' in src, 'Missing override_active guard'
# Check forecast reliability updates
assert 'forecast_reliability' in src and 'update' in src, 'Missing forecast_reliability update calls'
# Check pv_reliability_factor
assert 'pv_reliability_factor' in src, 'Missing pv_reliability_factor wiring'
print('PASS: main.py Phase 8 wiring verified')
"
    </automated>
    <manual>Verify main.py imports all Phase 8 modules, has shadow mode branching, forecast reliability updates, and confidence factor wiring</manual>
  </verify>
  <done>All four learners instantiated and wired into main.py: ResidualRLAgent with shadow/advisory branching, SeasonalLearner updating each cycle, ForecastReliabilityTracker feeding confidence into planner and buffer, ReactionTimingTracker classifying deviations. Override guard prevents RL logging during boost. Auto-promotion check runs when shadow period elapsed.</done>
</task>

</tasks>

<verification>
1. ReactionTimingTracker class exists with EMA-based self-correction rate
2. main.py imports and initializes all four Phase 8 learners
3. Shadow mode gates RL correction application (shadow = log only, advisory = apply)
4. Override active check prevents RL pollution during boost (Pitfall 5)
5. ForecastReliabilityTracker.update() called for PV (in kW), consumption, and price each cycle
6. Confidence factors passed to HorizonPlanner.plan()
7. PV reliability factor passed to DynamicBufferCalc.step()
8. SeasonalLearner.update() called with plan_error using slot-0 cost (not full-horizon)
9. ReactionTimingTracker.update() called with plan_action vs actual_action
10. Comparator.compare_residual() called with slot-0 costs
</verification>

<success_criteria>
- All Phase 8 learners initialize with graceful fallback (None if import/init fails)
- Decision loop continues to work when any learner is None
- Shadow mode RL path logs corrections without applying them
- Advisory mode RL path applies corrections with safety constraints
- Forecast confidence factors reduce planner aggressiveness when forecasts are unreliable
- PV reliability factor increases buffer conservatism when PV forecast is unreliable
</success_criteria>

<output>
After completion, create `.planning/phases/08-residual-rl-and-learning/08-03-SUMMARY.md`
</output>
